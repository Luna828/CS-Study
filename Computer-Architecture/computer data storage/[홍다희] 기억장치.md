
# 기억 장치 

모든 컴퓨터 시스템들은 프로그램과 데이터를 저장하기 위한 장치로서 **주기억장치**와 **보조저장장치**를 가지고 있다. 그러나 최근 CPU와 기억장치들 간의 속도 차이가 커지고 필요한 저장 용량이 증가함에 따라, 시스템 성능을 향상시키고 가격대성능비를 개선하기 위하여 다양한 유형의 기억장치들을 시스템에 포함시키고 있다. <br>

기억 장치는 CPU가 직접 엑세스 할 수 있는 **내부 기억장치**와 장치 제어기를 통하여 엑세스할 수 있는 **외부 기억장치**로 구성된다. 

# 기억 장치의 분류와 특성

CPU가 어떤 정보를 기억장치에 쓰거나 기억장치로부터 읽는 동작을 엑세스한다고 말한다. 기억 장치는 제조 공정과 재료 및 조직에 따라 액세스하는 방법도 달라지는데, 기억장치의 엑세스 유형은 일반적으로 다음과 같디 분류된다. 

### 순차적 엑세스

기억 장치에 저장된 정보들을 처음부터 순서대로 엑세스 한다. 자기 데이프 저장 장치가 이 방식을 이용하는데, 저장되는 모든 정보는 테이프의 처음 위치에서 시작하여 연속적으로 위치하게 된다. 그 내용들은 내부적으로 레코드(record)라고 불리는 정보 단위로 분리되어 저장되고, 각 레코드는 고유의 주소를 가진다. <br>

테이프의 전체 내용을 읽거나 쓰는 경우에는 처음부터 시작하면 되지만, 테이프 내 임의의 위치에 저장된 특정 정보를 읽기 위해서는 그 위치에 도달할떄까지 앞부분의 테이프를 모두 통과해야 한다. 따라서 정보가 저장된 위치에 따라 엑세스 시간이 달라진다. 

### 직접 엑세스 

이 엑세스 방식에서는 읽기/쓰기 장치가 각 레코드의 근처로 직접 이동한 후에 순차적 검색을 통하여 최종 위치에 도달한다. 이 방식에서도 엑세스 시간은 정보의 저장 위치에 도달한다. 이 방식에서도 엑세스 시간은 정보의 저장 위치에 다라 가변적이다.  

### 임의 엑세스

기억장치 내의 모든 저장 장소들을 고유의 주소를 가지고 있으며, 별도의 읽기/쓰기 회로를 가지고 있다. 따라서 어떤 위치든 임의로 선택될 수 있고, 직접 주소지정 되고, 엑세스될 수 있다. 결과적으로, 기억장치 내의 어떤 위치를 엑세스하는 그에 걸리는 시간이 항상 일정하다. 반도체 기억장치들이 임의 엑세스 방식을 이용한다. 

### 연관 엑세스 

임의 엑세스이 변형으로서, 각 기억 장소에는 키값에 해당하는 비트들이 데이터와 함께 저장되어 있다. 엑세스 요구에는 주소 대신에 원하는 비트 패턴이 포함되어 있는데, 그 비트들과 각 기억장소의 키 비튿르을 비교하여, 일치하는 기억 장소의 데이터가 읽혀져 출력된다. 키값의 비교에 걸리는 시간은 기억 장소의 위치에 관계없이 일정하다. 그러나 입력 비트 패턴과 키값들을 한 개씩 순차적으로 비교하면 시간이 많이 걸리기 때문에, 일반적으로 모든 기억 장소의 키값들을 동시에 비교할수 있는 하드웨어를 포함하고 있다. 

# 기억 장치 시스템 주요 파라미터 

### 엑세스 시간 

주소와 읽기/쓰기 신호가 기억장치에 도착하는 순간부터 데이터가 저장되거나 읽혀지는 동작이 완료되는 순간까지의 시간을 말한다. 임의 엑세스 기억장치와 경우에는 엑세스 시간이 모든 기억 장소들에 대하여 동일하지만, 순차적 혹은 직접 엑세스 기억장치의 경우에는 데이터가 저장되어 있는 위치에 따라 달라진다. 

### 기억장치 사이클 시간 

이 시간은 엑세스 시간과 다음 엑세스를 시작하기 위해 필요한 동작에 걸리는 추가적인 시간을 합한 시간이다. 여기서 추가적인 시간이란 읽기 동작 후에 정보가 소멸되는 저장장치인 경우에 그것을 복원시키는 데 걸리는 시간을 말한다. 과거에 사용되던 자가코어나 최근에 개발되고 있는 FRAM은 읽기 동작 후에 내영이 지워지며, 자동적으로 다시 복구되지만 일정 시간이 소요된다. 

### 데이터 전송률 

이것은 기억장치로부터 초당 읽혀지거나 쓰여질 수 있는 비트 수를 말한다. 따라서 이것은 (1/엑세스 시간)x(한 번에 읽혀지는 데이터 바이트의 수)에 의해 구할 수 있다. 예를 들어, 어떤 RAM 모듈의 엑세스 시간이 100ns이고, 한 번에 32비트씩 읽혀진다면, 데이터 전송률은 (1/(100x10^-9))x(32/8) = 40[MBytes/sec]가 된다. 

# 계층적 기억장치시스템 

전체 기억장치를 구성하는데 있어서 가격은 최소화 하면서 가능한 속도는 빠른 접근속도와 대용량의 크기를 제공하기 위해→ 입출력의 경제성 확보된다. 레지스터, 캐시, 메모리, 하드 디스크는 하드웨어적으로 만들어지는 방법이 다를 때가 많다. 그리고 메모리 구조에서 상층에 속할수록 더 비싸다. 비싼 하드웨어는 꼭 필요한 만큼의 크기만 사용하고, 싼 하드웨어를 넉넉한 크기만큼 사용하기 때문에 메모리 계층 구조가 피라미드 모양으로 나타나는 것이다.

![image](https://github.com/hdaisywd/hdaisywd/assets/102342953/41e435bb-0595-4818-a4c1-488e27375f7a)

**상위 층**으로 갈수록 비트당 가격이 높아지고, 용량은 감소하며, 엑세스 시간이 짧아지고, CPU에 의한 엑세스 빈도 상승한다. **하위 층**으로 갈수록 비트당 가격이 떨어지고, 용량은 커지며, 지역성의 원리로 인하여 엑세스 빈도가 더 낮아진다. 

> 캐시(Cache)란? <br>
> 캐시는 얻고자 하는 데이터를 필요한 순간마다 데이터가 저장되어 있는 저장소에서 가져오는 일에 대한 시간을 줄일 때 사용되는 임시 저장소이다. = 즉, 사용되었던 데이터는 다시 사용되어질 가능성이 높다는 개념 을 이용하여, 다시 사용될 확률이 높은 것은 더 빠르게 접근 가능한 저장소를 사용한다는 개념이다. <br>
> 캐시기억장치는 중앙처리장치가 주기억장치에서 필요한 데이터를 가져와야 할 때 미리 캐시기억장치에 그 내용을 저장해 두고 중앙처리장치가 주기억장치에 접근하는 대신 캐시기억장치에서 데이터를 가져오게 함으로써, 중앙처리장치와 주기억장치 간의 속도 차이 개선을 목적으로 한다. <br>
> CPU 단에서 캐시 메모리는 전반적인 시스템 성능을 개선하기 위한 방법으로 높은 성능의 메모리를 개발하는 대신 CPU와 가까운 위치에 용량을 작게하여 빠른 액세스 가능한 메모리를 두는 것이다. 캐시가 없던 시절에는 데이터를 메모리에서 레지스터로 바로 가져왔었는데, 레지스터에서 CPU로 데이터를 가져올 때는 1 사이클이 걸리는 데에 반해 메인 메모리에서부터는 100 사이클 정도가 걸린다고 보면 CPU의 데이터 요청 속도가 빨라지면서 이 시간이 매우 부담스러워지게 된 것이다. 아무리 CPU 성능이 좋아서 연산 속도가 빨라진다 해도 연산에 필요한 데이터가 메인메모리에서 레지스터로 옮겨지기까지 기다려야 하기 때문이다. 그래서 생기게 된 것이 바로 캐시메모리이다. 캐시메모리는 CPU에 레지스터와 메인메모리 사이에 위치하고 있다.

<img width="769" alt="image" src="https://github.com/hdaisywd/hdaisywd/assets/102342953/292b1a95-fa63-4533-b547-08e26838b63d">